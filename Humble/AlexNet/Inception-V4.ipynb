{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breeding-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Activation, Input, concatenate, Dropout, Dense, Flatten\n",
    "from keras.layers import MaxPooling2D, Conv2D, AveragePooling2D, BatchNormalization\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "def block_stem(inputs):\n",
    "    net = conv2d(inputs, 32, (3, 3), strides=(2, 2), padding='valid')\n",
    "    net = conv2d(net, 32, (3, 3), padding='valid')\n",
    "    net = conv2d(net, 64, (3, 3))\n",
    "\n",
    "    branch_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(net)\n",
    "    branch_2 = conv2d(net, 96, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_1, branch_2])\n",
    "\n",
    "    branch_1 = conv2d(net, 64, (1, 1))\n",
    "    branch_1 = conv2d(branch_1, 96, (3, 3), padding='valid')\n",
    "\n",
    "    branch_2 = conv2d(net, 64, (1, 1))\n",
    "    branch_2 = conv2d(branch_2, 64, (7, 1))\n",
    "    branch_2 = conv2d(branch_2, 64, (1, 7))\n",
    "    branch_2 = conv2d(branch_2, 96, (3, 3), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_1, branch_2])\n",
    "\n",
    "    branch_1 = conv2d(net, 192, (3, 3), strides=(2, 2), padding='valid')  # different from the paper\n",
    "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(net)\n",
    "\n",
    "    net = concatenate([branch_1, branch_2])\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def block_inception_a(inputs):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    branch_1 = conv2d(branch_1, 96, (1, 1))\n",
    "\n",
    "    branch_2 = conv2d(inputs, 96, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d(inputs, 64, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 96, (3, 3))\n",
    "\n",
    "    branch_4 = conv2d(inputs, 64, (1, 1))\n",
    "    branch_4 = conv2d(branch_4, 96, (3, 3))\n",
    "    branch_4 = conv2d(branch_4, 96, (3, 3))\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3, branch_4])\n",
    "\n",
    "\n",
    "def block_inception_b(inputs):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    branch_1 = conv2d(branch_1, 128, (1, 1))\n",
    "\n",
    "    branch_2 = conv2d(inputs, 384, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 224, (1, 7))\n",
    "    branch_3 = conv2d(branch_3, 256, (7, 1))  # different from the paper\n",
    "\n",
    "    branch_4 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_4 = conv2d(branch_4, 192, (1, 7))\n",
    "    branch_4 = conv2d(branch_4, 224, (7, 1))\n",
    "    branch_4 = conv2d(branch_4, 224, (1, 7))\n",
    "    branch_4 = conv2d(branch_4, 256, (7, 1))\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3, branch_4])\n",
    "\n",
    "\n",
    "def block_inception_c(inputs):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    branch_1 = conv2d(branch_1, 256, (1, 1))\n",
    "\n",
    "    branch_2 = conv2d(inputs, 256, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d(inputs, 384, (1, 1))\n",
    "    branch_3_1 = conv2d(branch_3, 256, (1, 3))\n",
    "    branch_3_2 = conv2d(branch_3, 256, (3, 1))\n",
    "\n",
    "    branch_4 = conv2d(inputs, 384, (1, 1))\n",
    "    branch_4 = conv2d(branch_4, 448, (1, 3))\n",
    "    branch_4 = conv2d(branch_4, 512, (3, 1))\n",
    "    branch_4_1 = conv2d(branch_4, 256, (3, 1))\n",
    "    branch_4_2 = conv2d(branch_4, 256, (1, 3))\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3_1, branch_3_2, branch_4_1, branch_4_2])\n",
    "\n",
    "\n",
    "def block_reduction_a(inputs):\n",
    "    branch_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(inputs)\n",
    "\n",
    "    branch_2 = conv2d(inputs, 384, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_3 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 224, (3, 3))\n",
    "    branch_3 = conv2d(branch_3, 256, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3])\n",
    "\n",
    "\n",
    "def block_reduction_b(inputs):\n",
    "    branch_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(inputs)\n",
    "\n",
    "    branch_2 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_2 = conv2d(branch_2, 192, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_3 = conv2d(inputs, 256, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 256, (1, 7))\n",
    "    branch_3 = conv2d(branch_3, 320, (7, 1))\n",
    "    branch_3 = conv2d(branch_3, 320, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3])\n",
    "\n",
    "\n",
    "def conv2d(net, filters, kernel_size, strides=(1, 1), padding='same'):\n",
    "    net = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    net = Activation('relu')(net)\n",
    "    return net\n",
    "\n",
    "def create(classes_num=4):\n",
    "    inputs = Input((227, 227, 3))\n",
    "\n",
    "    # 227 x 227 x 3\n",
    "    net = block_stem(inputs)\n",
    "\n",
    "    # 4 x Inception-A ( Output: 35 x 35 x 384 )\n",
    "    for i in range(4):\n",
    "        net = block_inception_a(net)\n",
    "\n",
    "    # Reduction-A ( Output: 17 x 17 x 1024 )\n",
    "    net = block_reduction_a(net)\n",
    "\n",
    "    # 7 x Inception-B ( Output: 17 x 17 x 1024 )\n",
    "    for i in range(7):\n",
    "        net = block_inception_b(net)\n",
    "\n",
    "    # Reduction-B ( Output: 8 x 8 x 1536 )\n",
    "    net = block_reduction_b(net)\n",
    "\n",
    "    # 3 x Inception-C ( Output: 8 x 8 x 1536 )\n",
    "    for i in range(3):\n",
    "        net = block_inception_c(net)\n",
    "\n",
    "    # Average Pooling ( Output: 1536 )\n",
    "    net = AveragePooling2D((5, 5))(net)\n",
    "\n",
    "    # Dropout ( keep 0.8 )\n",
    "    net = Dropout(0.2)(net)\n",
    "    net = Flatten()(net)\n",
    "\n",
    "    # Output\n",
    "    outputs = Dense(units=classes_num, activation='softmax')(net)\n",
    "\n",
    "    return Model(inputs, outputs, name='Inception-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "possible-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inceptionV4_model(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # validation split\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1, random_state=10,\n",
    "                                                                    stratify=y_train)\n",
    "    print(len(X_train))\n",
    "\n",
    "\n",
    "    model = create()\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "                  optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_validation, y_validation))\n",
    "    \n",
    "    evaluation = []\n",
    "    evaluation.append(model.evaluate(X_train, y_train, batch_size=16))\n",
    "    evaluation.append(model.evaluate(X_test, y_test, batch_size=16))\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "threaded-turkey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 227, 3)\n",
      "720\n",
      "518\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 57s 974ms/step - loss: 1.4217 - accuracy: 0.3649 - val_loss: 937.1095 - val_accuracy: 0.2414\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 1.0640 - accuracy: 0.5646 - val_loss: 74.7931 - val_accuracy: 0.2414\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.9254 - accuracy: 0.6186 - val_loss: 21.6783 - val_accuracy: 0.3276\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.8077 - accuracy: 0.6177 - val_loss: 22.0403 - val_accuracy: 0.2414\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.6658 - accuracy: 0.6963 - val_loss: 4.4057 - val_accuracy: 0.4655\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.6580 - accuracy: 0.7158 - val_loss: 1.9448 - val_accuracy: 0.4310\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.5948 - accuracy: 0.7547 - val_loss: 1.5379 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.4959 - accuracy: 0.7739 - val_loss: 0.8495 - val_accuracy: 0.5517\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.6157 - accuracy: 0.7306 - val_loss: 0.8278 - val_accuracy: 0.6552\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.4183 - accuracy: 0.8360 - val_loss: 1.2384 - val_accuracy: 0.6379\n",
      "33/33 [==============================] - 2s 59ms/step - loss: 1.1802 - accuracy: 0.7375\n",
      "9/9 [==============================] - 2s 57ms/step - loss: 0.9125 - accuracy: 0.7222\n",
      "518\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 14s 241ms/step - loss: 1.3308 - accuracy: 0.3708 - val_loss: 2409.3455 - val_accuracy: 0.2414\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 1.0364 - accuracy: 0.5427 - val_loss: 301.4019 - val_accuracy: 0.2586\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.7814 - accuracy: 0.6550 - val_loss: 178.4928 - val_accuracy: 0.2586\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.7490 - accuracy: 0.6399 - val_loss: 74.6758 - val_accuracy: 0.2586\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.6897 - accuracy: 0.7001 - val_loss: 40.7843 - val_accuracy: 0.2586\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.7860 - accuracy: 0.6717 - val_loss: 18.3547 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.6185 - accuracy: 0.7332 - val_loss: 66.5722 - val_accuracy: 0.2586\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.5707 - accuracy: 0.7387 - val_loss: 1.5632 - val_accuracy: 0.5172\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.5312 - accuracy: 0.7639 - val_loss: 1.7471 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.5528 - accuracy: 0.7622 - val_loss: 1.3453 - val_accuracy: 0.5172\n",
      "33/33 [==============================] - 2s 58ms/step - loss: 1.2101 - accuracy: 0.5830\n",
      "9/9 [==============================] - 2s 58ms/step - loss: 1.2543 - accuracy: 0.5556\n",
      "518\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 14s 244ms/step - loss: 1.4916 - accuracy: 0.3514 - val_loss: 1531.0291 - val_accuracy: 0.2586\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 1.1419 - accuracy: 0.5103 - val_loss: 326.4311 - val_accuracy: 0.2414\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.9498 - accuracy: 0.6102 - val_loss: 79.9273 - val_accuracy: 0.2414\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 1.0302 - accuracy: 0.5308 - val_loss: 96.4948 - val_accuracy: 0.2586\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.7687 - accuracy: 0.6961 - val_loss: 62.6340 - val_accuracy: 0.2586\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.7775 - accuracy: 0.6752 - val_loss: 58.9085 - val_accuracy: 0.2759\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.8040 - accuracy: 0.6833 - val_loss: 9.7971 - val_accuracy: 0.4138\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.7268 - accuracy: 0.6647 - val_loss: 6.5134 - val_accuracy: 0.5690\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.6886 - accuracy: 0.7353 - val_loss: 1.5771 - val_accuracy: 0.7241\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.6209 - accuracy: 0.7409 - val_loss: 2.1865 - val_accuracy: 0.6034\n",
      "33/33 [==============================] - 2s 59ms/step - loss: 1.4590 - accuracy: 0.7124\n",
      "9/9 [==============================] - 2s 59ms/step - loss: 1.3950 - accuracy: 0.6528\n",
      "518\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 14s 241ms/step - loss: 1.4278 - accuracy: 0.3425 - val_loss: 431.4727 - val_accuracy: 0.2586\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 1.0751 - accuracy: 0.5781 - val_loss: 40.7644 - val_accuracy: 0.2586\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.8607 - accuracy: 0.6042 - val_loss: 13.4433 - val_accuracy: 0.4828\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.7689 - accuracy: 0.6624 - val_loss: 8.0343 - val_accuracy: 0.2586\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.7436 - accuracy: 0.6530 - val_loss: 3.9997 - val_accuracy: 0.3276\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.6949 - accuracy: 0.6829 - val_loss: 2.7142 - val_accuracy: 0.5345\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.7044 - accuracy: 0.6797 - val_loss: 1.2188 - val_accuracy: 0.6207\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.5611 - accuracy: 0.7887 - val_loss: 1.7593 - val_accuracy: 0.7414\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.4711 - accuracy: 0.8121 - val_loss: 0.9268 - val_accuracy: 0.6207\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.5819 - accuracy: 0.7577 - val_loss: 1.6402 - val_accuracy: 0.6379\n",
      "33/33 [==============================] - 2s 59ms/step - loss: 1.9361 - accuracy: 0.6776\n",
      "9/9 [==============================] - 2s 59ms/step - loss: 1.6878 - accuracy: 0.6319\n",
      "518\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 14s 243ms/step - loss: 1.5635 - accuracy: 0.3626 - val_loss: 699.7664 - val_accuracy: 0.2414\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 203ms/step - loss: 1.1075 - accuracy: 0.5103 - val_loss: 273.4078 - val_accuracy: 0.2414\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 203ms/step - loss: 0.9828 - accuracy: 0.5916 - val_loss: 69.5850 - val_accuracy: 0.2414\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.8994 - accuracy: 0.6137 - val_loss: 37.2663 - val_accuracy: 0.2586\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.7583 - accuracy: 0.6628 - val_loss: 31.6670 - val_accuracy: 0.2586\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.7231 - accuracy: 0.6779 - val_loss: 6.3533 - val_accuracy: 0.2586\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.7243 - accuracy: 0.7041 - val_loss: 2.5475 - val_accuracy: 0.2931\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.6846 - accuracy: 0.6782 - val_loss: 0.9244 - val_accuracy: 0.6379\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.6245 - accuracy: 0.7328 - val_loss: 3.7913 - val_accuracy: 0.4310\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.5711 - accuracy: 0.7648 - val_loss: 1.0769 - val_accuracy: 0.5862\n",
      "33/33 [==============================] - 2s 59ms/step - loss: 0.8969 - accuracy: 0.6390\n",
      "9/9 [==============================] - 2s 59ms/step - loss: 1.0814 - accuracy: 0.6736\n",
      "518\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 14s 241ms/step - loss: 1.4774 - accuracy: 0.3142 - val_loss: 2854.2207 - val_accuracy: 0.2586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 1.0285 - accuracy: 0.5289 - val_loss: 486.1802 - val_accuracy: 0.2586\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.8865 - accuracy: 0.6010 - val_loss: 229.0485 - val_accuracy: 0.2414\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.8163 - accuracy: 0.6726 - val_loss: 40.1949 - val_accuracy: 0.2586\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.7458 - accuracy: 0.6929 - val_loss: 144.4328 - val_accuracy: 0.2414\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.6872 - accuracy: 0.7385 - val_loss: 23.0821 - val_accuracy: 0.2586\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.5454 - accuracy: 0.7908 - val_loss: 22.5118 - val_accuracy: 0.2586\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 200ms/step - loss: 0.4914 - accuracy: 0.8099 - val_loss: 5.1302 - val_accuracy: 0.4310\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.5158 - accuracy: 0.7839 - val_loss: 1.2665 - val_accuracy: 0.5862\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.3551 - accuracy: 0.8506 - val_loss: 0.7080 - val_accuracy: 0.6552\n",
      "33/33 [==============================] - 2s 59ms/step - loss: 0.6674 - accuracy: 0.6931\n",
      "9/9 [==============================] - 2s 59ms/step - loss: 0.7146 - accuracy: 0.6736\n",
      "518\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 14s 241ms/step - loss: 1.3757 - accuracy: 0.3925 - val_loss: 218.4483 - val_accuracy: 0.2586\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.9937 - accuracy: 0.5482 - val_loss: 65.2360 - val_accuracy: 0.2586\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.8075 - accuracy: 0.6259 - val_loss: 42.4371 - val_accuracy: 0.2586\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 202ms/step - loss: 0.8505 - accuracy: 0.6749 - val_loss: 47.2114 - val_accuracy: 0.2414\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.7433 - accuracy: 0.7152 - val_loss: 15.7773 - val_accuracy: 0.4828\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.6358 - accuracy: 0.7296 - val_loss: 19.0482 - val_accuracy: 0.2586\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 201ms/step - loss: 0.6978 - accuracy: 0.7553 - val_loss: 11.5905 - val_accuracy: 0.5345\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.6117 - accuracy: 0.7739 - val_loss: 1.1305 - val_accuracy: 0.5862\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 208ms/step - loss: 0.4317 - accuracy: 0.8383 - val_loss: 0.9702 - val_accuracy: 0.7241\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 211ms/step - loss: 0.6020 - accuracy: 0.7686 - val_loss: 1.2705 - val_accuracy: 0.6207\n",
      "33/33 [==============================] - 2s 60ms/step - loss: 1.1164 - accuracy: 0.6892\n",
      "9/9 [==============================] - 2s 60ms/step - loss: 0.9940 - accuracy: 0.6597 0s - loss: 1.0191 - accura\n",
      "518\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 14s 251ms/step - loss: 1.6121 - accuracy: 0.3170 - val_loss: 752.8146 - val_accuracy: 0.2414\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 1.1655 - accuracy: 0.5602 - val_loss: 277.0565 - val_accuracy: 0.2414\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.9486 - accuracy: 0.5780 - val_loss: 121.6596 - val_accuracy: 0.2414\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.8963 - accuracy: 0.6052 - val_loss: 29.5305 - val_accuracy: 0.2414\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.7513 - accuracy: 0.6739 - val_loss: 51.5194 - val_accuracy: 0.2586\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.7863 - accuracy: 0.6885 - val_loss: 9.5570 - val_accuracy: 0.2586\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.6958 - accuracy: 0.6846 - val_loss: 3.6070 - val_accuracy: 0.2414\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.7400 - accuracy: 0.6813 - val_loss: 6.3680 - val_accuracy: 0.4310\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.6870 - accuracy: 0.7207 - val_loss: 7.0168 - val_accuracy: 0.4828\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.5557 - accuracy: 0.7648 - val_loss: 1.7329 - val_accuracy: 0.6379\n",
      "33/33 [==============================] - 2s 59ms/step - loss: 1.3558 - accuracy: 0.6776\n",
      "9/9 [==============================] - 2s 60ms/step - loss: 1.4223 - accuracy: 0.6250\n",
      "518\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 14s 248ms/step - loss: 1.4070 - accuracy: 0.3113 - val_loss: 712.8557 - val_accuracy: 0.2414\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 1.1322 - accuracy: 0.4906 - val_loss: 263.5127 - val_accuracy: 0.2586\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.9693 - accuracy: 0.6037 - val_loss: 72.7035 - val_accuracy: 0.2586\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.8437 - accuracy: 0.6547 - val_loss: 88.4433 - val_accuracy: 0.2414\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.7730 - accuracy: 0.6927 - val_loss: 11.8292 - val_accuracy: 0.2414\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.7693 - accuracy: 0.6821 - val_loss: 12.7650 - val_accuracy: 0.2241\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.7873 - accuracy: 0.6688 - val_loss: 18.9578 - val_accuracy: 0.1724\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.5564 - accuracy: 0.7860 - val_loss: 1.0712 - val_accuracy: 0.5345\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.4980 - accuracy: 0.8033 - val_loss: 0.6661 - val_accuracy: 0.6897\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.4139 - accuracy: 0.8118 - val_loss: 1.8836 - val_accuracy: 0.6379\n",
      "33/33 [==============================] - 2s 60ms/step - loss: 1.0386 - accuracy: 0.7162\n",
      "9/9 [==============================] - 2s 60ms/step - loss: 0.8509 - accuracy: 0.6944\n",
      "518\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 14s 248ms/step - loss: 1.3971 - accuracy: 0.3172 - val_loss: 2040.3953 - val_accuracy: 0.2414\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 1.0219 - accuracy: 0.5650 - val_loss: 304.2174 - val_accuracy: 0.2414\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.7270 - accuracy: 0.6978 - val_loss: 120.7448 - val_accuracy: 0.2414\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.7487 - accuracy: 0.6667 - val_loss: 144.4240 - val_accuracy: 0.2414\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.6543 - accuracy: 0.7099 - val_loss: 18.2964 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 7s 208ms/step - loss: 0.5572 - accuracy: 0.7915 - val_loss: 23.1877 - val_accuracy: 0.2414\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.5061 - accuracy: 0.7889 - val_loss: 2.1649 - val_accuracy: 0.4483\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 7s 208ms/step - loss: 0.4838 - accuracy: 0.8361 - val_loss: 2.0142 - val_accuracy: 0.7069\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 7s 207ms/step - loss: 0.3230 - accuracy: 0.8677 - val_loss: 1.2365 - val_accuracy: 0.7759\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 7s 206ms/step - loss: 0.3296 - accuracy: 0.8553 - val_loss: 0.5891 - val_accuracy: 0.7759\n",
      "33/33 [==============================] - 2s 60ms/step - loss: 0.8242 - accuracy: 0.7201\n",
      "9/9 [==============================] - 2s 60ms/step - loss: 0.6214 - accuracy: 0.7361\n"
     ]
    }
   ],
   "source": [
    "image_size = 227\n",
    "\n",
    "groups_folder_path = '../Data/resultVecsFigs/AAFT_3/'\n",
    "\n",
    "X_s = []\n",
    "\n",
    "y = []\n",
    "# auto_corr   hadamard     midAng    striping_color   striping_bw     striping_midAng_color     striping_midAng_bw\n",
    "for label in ['Bi', 'Tri', 'Hammer', 'Rvcurl']:\n",
    "\n",
    "    for feature in ['hadamard']:\n",
    "\n",
    "        for top, dir, f in os.walk(groups_folder_path + label + \"/\" + feature + \"/\"):\n",
    "            # print(f)\n",
    "            for filename in f:\n",
    "                # print(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.imread(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.resize(img, None, fx=image_size / img.shape[0], fy=image_size / img.shape[1])\n",
    "\n",
    "                X_s.append(img / 256)\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                elif label =='Tri':\n",
    "                    y.append(1)\n",
    "                elif label == 'Hammer':\n",
    "                    y.append(2)\n",
    "                else:\n",
    "                    y.append(3)\n",
    "\n",
    "print(X_s[0].shape)\n",
    "# print(X_s)\n",
    "print(len(y))\n",
    "X = np.array(X_s)\n",
    "y = np.array(y)\n",
    "\n",
    "ins = []\n",
    "for i in range(10):\n",
    "    ins.append(inceptionV4_model(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.180242896080017\n",
      "1.2101414203643799\n",
      "1.4589647054672241\n",
      "1.936052918434143\n",
      "0.8968687057495117\n",
      "0.6674296855926514\n",
      "1.116393804550171\n",
      "1.3558123111724854\n",
      "1.0385794639587402\n",
      "0.824177622795105\n"
     ]
    }
   ],
   "source": [
    "for data in ins:\n",
    "    print(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hispanic-paraguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222222089767456\n",
      "0.5555555820465088\n",
      "0.6527777910232544\n",
      "0.6319444179534912\n",
      "0.6736111044883728\n",
      "0.6736111044883728\n",
      "0.6597222089767456\n",
      "0.625\n",
      "0.6944444179534912\n",
      "0.7361111044883728\n"
     ]
    }
   ],
   "source": [
    "for data in ins:\n",
    "    print(data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appreciated-latitude",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngroups_folder_path = \\'../Data/resultVecsFigs/AAFT_4/\\'\\nX_s = []\\ny = []\\n# auto_corr   hadamard     midAng    striping_color   striping_bw     striping_midAng_color     striping_midAng_bw\\nfor label in [\\'Bi\\', \\'Tri\\']:\\n\\n    for feature in [\\'hadamard\\']:\\n\\n        for top, dir, f in os.walk(groups_folder_path + label + \"/\" + feature + \"/\"):\\n            # print(f)\\n            for filename in f:\\n                # print(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\\n                img = cv2.imread(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\\n                img = cv2.resize(img, None, fx=image_size / img.shape[0], fy=image_size / img.shape[1])\\n\\n                X_s.append(img / 256)\\n\\n                if label == \\'Bi\\':\\n                    y.append(0)\\n                else:\\n                    y.append(1)\\n\\nprint(X_s[0].shape)\\n# print(X_s)\\nprint(len(y))\\nX = np.array(X_s)\\ny = np.array(y)\\n\\nins = []\\nfor i in range(10):\\n    ins.append(inceptionV4_model(X, y))\\n\\nfor data in ins:\\n    for d in data:\\n        for j in d:\\n            print(j)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "groups_folder_path = '../Data/resultVecsFigs/AAFT_4/'\n",
    "X_s = []\n",
    "y = []\n",
    "# auto_corr   hadamard     midAng    striping_color   striping_bw     striping_midAng_color     striping_midAng_bw\n",
    "for label in ['Bi', 'Tri']:\n",
    "\n",
    "    for feature in ['hadamard']:\n",
    "\n",
    "        for top, dir, f in os.walk(groups_folder_path + label + \"/\" + feature + \"/\"):\n",
    "            # print(f)\n",
    "            for filename in f:\n",
    "                # print(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.imread(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.resize(img, None, fx=image_size / img.shape[0], fy=image_size / img.shape[1])\n",
    "\n",
    "                X_s.append(img / 256)\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    y.append(1)\n",
    "\n",
    "print(X_s[0].shape)\n",
    "# print(X_s)\n",
    "print(len(y))\n",
    "X = np.array(X_s)\n",
    "y = np.array(y)\n",
    "\n",
    "ins = []\n",
    "for i in range(10):\n",
    "    ins.append(inceptionV4_model(X, y))\n",
    "\n",
    "for data in ins:\n",
    "    for d in data:\n",
    "        for j in d:\n",
    "            print(j)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
